# Gran Sabio LLM Engine - Environment Variables Template
# =====================================================
# Copy this file to .env and fill in your API keys

# Required API Keys for AI Services
# =================================

# OpenAI API Key (for GPT models)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API Key (for Claude models)  
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-api03-your-anthropic-api-key-here

# Google AI API Key (for Gemini models)
# Get from: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your-google-ai-api-key-here

# xAI API Key (for Grok models)
# Get from: https://console.x.ai/
XAI_API_KEY=xai-your-xai-key-here

# Attachment Storage
# ==================
# Required for attachment functionality. Use any random string.
# This pepper is used to hash usernames for storage paths.
PEPPER=your-random-secret-pepper-here

# Optional Configuration
# =====================

# FastAPI Configuration
APP_HOST=0.0.0.0
APP_PORT=8000
APP_RELOAD=true

# Request Limits
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=120
MAX_RETRIES=5
RETRY_DELAY=15.0
RETRY_BACKOFF_MULTIPLIER=2.0
RETRY_MAX_DELAY=120.0
RETRY_JITTER=true

# Session Management
MAX_ACTIVE_SESSIONS=100
SESSION_TIMEOUT=3600
CLEANUP_INTERVAL=300

# Logging
LOG_LEVEL=INFO
VERBOSE_MAX_ENTRIES=100

# Default Models (optional - will use config.py defaults if not set)
DEFAULT_GENERATOR_MODEL=gpt-4o
DEFAULT_QA_MODELS=gpt-4o,claude-sonnet-4-20250514,gemini-2.0-flash
DEFAULT_GRAN_SABIO_MODEL=claude-opus
DEFAULT_CONSENSUS_MODEL=gpt-4o

# Quality Standards (optional)
DEFAULT_MIN_GLOBAL_SCORE=8.0
DEFAULT_MAX_ITERATIONS=5

# Smart Edit Configuration (optional)
# Maximum paragraphs that can be edited in a single smart edit iteration
MAX_PARAGRAPHS_PER_INCREMENTAL_RUN=12

# Maximum consecutive smart edit iterations before forcing full regeneration
DEFAULT_MAX_CONSECUTIVE_SMART_EDITS=10

# Evidence Grounding Configuration (optional)
# Model for claim extraction and verification (any supported model works)
# Examples: gpt-5-nano, meta-llama/llama-3.3-70b-instruct (OpenRouter), qwen2.5:14b (Ollama)
# For Phase 4 logprob verification, use models that support logprobs (not O1/O3/Claude)
EVIDENCE_GROUNDING_MODEL=gpt-5-nano